{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_path = 'models/square_model.tflite'\n",
    "BG_COLOR = (1, 1, 1) # gray\n",
    "MASK_COLOR = (0, 0, 0) # white\n",
    "base_options = python.BaseOptions(model_asset_path='model/square_model.tflite')\n",
    "options = vision.ImageSegmenterOptions(base_options=base_options, output_category_mask=True)\n",
    "segmenter = vision.ImageSegmenter.create_from_options(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs resizing and showing the image\n",
    "def resize_image(image):\n",
    "    # Height and width that will be used by the model\n",
    "    DESIRED_HEIGHT = 480\n",
    "    DESIRED_WIDTH = 480\n",
    "    h, w = image.shape[:2]\n",
    "    if h < w:\n",
    "        img = cv2.resize(image, (DESIRED_WIDTH, math.floor(h/(w/DESIRED_WIDTH))))\n",
    "    else:\n",
    "        img = cv2.resize(image, (math.floor(w/(h/DESIRED_HEIGHT)), DESIRED_HEIGHT))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_segments(image):\n",
    "    # Retrieve the masks for the segmented image\n",
    "    segmentation_result = segmenter.segment(image)\n",
    "    category_mask = segmentation_result.category_mask\n",
    "\n",
    "    # Generate solid color images for showing the output segmentation mask.\n",
    "    image_data = image.numpy_view()\n",
    "    fg_image = np.zeros(image_data.shape, dtype=np.uint8)\n",
    "    fg_image[:] = MASK_COLOR\n",
    "    bg_image = np.zeros(image_data.shape, dtype=np.uint8)\n",
    "    bg_image[:] = BG_COLOR\n",
    "\n",
    "    condition = np.stack((category_mask.numpy_view(),) * 3, axis=-1) > 0.2\n",
    "    segmented_image = np.where(condition, fg_image, bg_image)\n",
    "    return segmented_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "image = mp.Image.create_from_file(\"Images/b.jpg\")\n",
    "segmented_image = segmenter.segment(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4032"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def zoom_at(img, x, y, zoom):\n",
    "    w, h = img.size\n",
    "    zoom2 = zoom * 2\n",
    "    img = img.crop((x - w / zoom2, y - h / zoom2, \n",
    "                    x + w / zoom2, y + h / zoom2))\n",
    "    return img.resize((w, h), Image.LANCZOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4032"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the contours of the binary mask\n",
    "contours, hierarchy = cv2.findContours(segmentation_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Get the bounding box coordinates\n",
    "x,y,w,h = cv2.boundingRect(contours[0])\n",
    "center_x = int(x + w/2)\n",
    "center_y = int(y + h/2)\n",
    "\n",
    "img = zoom_at(img, 264.5, 275, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "FaceDetector = mp.tasks.vision.FaceDetector\n",
    "FaceDetectorOptions = mp.tasks.vision.FaceDetectorOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "# Create a face detector instance with the image mode:\n",
    "options = FaceDetectorOptions(\n",
    "    base_options=BaseOptions(model_asset_path='/path/to/model.task'),\n",
    "    running_mode=VisionRunningMode.IMAGE)\n",
    "with FaceDetector.create_from_options(options) as detector:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
